{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb9ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32c7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('reut2-*.sgm')\n",
    "all_texts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256d2dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 files matching pattern 'reut2-*.sgm'.\n",
      "Read 22 files.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(file_list)} files matching pattern 'reut2-*.sgm'.\")\n",
    "\n",
    "for file in file_list:\n",
    "    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        all_texts.append(f.read())\n",
    "\n",
    "print(f\"Read {len(all_texts)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f8bbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_file_content = all_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d2cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(first_file_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc2cfe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.find_all('reuters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b2e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters in the article body: 937333\n"
     ]
    }
   ],
   "source": [
    "all_article_text = \" \".join(article.get_text() for article in articles)\n",
    "clean_text = ' '.join(all_article_text.split())\n",
    "print(f\"Total characters in the article body: {len(clean_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92045c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total tokens in the article body: 152991\n"
     ]
    }
   ],
   "source": [
    "tokens = clean_text.split()\n",
    "print(f\"\\nTotal tokens in the article body: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7cc23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ next_word_freq function defined\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "def next_word_freq(token_array, input_sentence):\n",
    "    sentence_tokens = input_sentence.split()\n",
    "    sentence_length = len(sentence_tokens)\n",
    "    following_words = []\n",
    "    \n",
    "    for i in range(len(token_array) - sentence_length):\n",
    "        current_sequence = ' '.join(token_array[i:i + sentence_length])\n",
    "        \n",
    "        if current_sequence.lower() == input_sentence.lower():\n",
    "            if i + sentence_length < len(token_array):\n",
    "                following_words.append(token_array[i + sentence_length])\n",
    "    \n",
    "    return dict(Counter(following_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ecc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ calculate_cdf function defined\n"
     ]
    }
   ],
   "source": [
    "def calculate_cdf(frequency_dict):\n",
    "    if not frequency_dict:\n",
    "        return {}\n",
    "    \n",
    "    total_frequency = sum(frequency_dict.values())\n",
    "    cumulative_prob = 0\n",
    "    cdf_dict = {}\n",
    "    \n",
    "    for word, frequency in frequency_dict.items():\n",
    "        pmf = frequency / total_frequency\n",
    "        cumulative_prob += pmf\n",
    "        cdf_dict[word] = cumulative_prob\n",
    "    \n",
    "    return cdf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19988e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ predict_next_word function defined\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(cdf_dict):\n",
    "    if not cdf_dict:\n",
    "        return None\n",
    "    \n",
    "    random_number = random.uniform(0, 1)\n",
    "    \n",
    "    for word, cdf_value in cdf_dict.items():\n",
    "        if random_number <= cdf_value:\n",
    "            return word\n",
    "    \n",
    "    return list(cdf_dict.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c84a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ generate_text function defined\n"
     ]
    }
   ],
   "source": [
    "def generate_text(starting_word, target_length=10, corpus_tokens=None):\n",
    "    if corpus_tokens is None:\n",
    "        corpus_tokens = tokens\n",
    "    \n",
    "    current_phrase = starting_word\n",
    "    generated_text = starting_word\n",
    "    words_generated = len(starting_word.split())\n",
    "    \n",
    "    while words_generated < target_length:\n",
    "        word_frequencies = next_word_freq(corpus_tokens, current_phrase)\n",
    "        \n",
    "        if not word_frequencies:\n",
    "            break\n",
    "        \n",
    "        cdf_dict = calculate_cdf(word_frequencies)\n",
    "        next_word = predict_next_word(cdf_dict)\n",
    "        \n",
    "        if next_word is None:\n",
    "            break\n",
    "        \n",
    "        generated_text += \" \" + next_word\n",
    "        current_phrase = next_word\n",
    "        words_generated += 1\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5e3b1",
   "metadata": {},
   "source": [
    "## Text Generation\n",
    "\n",
    "Test the text generation system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bb8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXAMPLE 1: Starting with 'the'\n",
      "============================================================\n",
      "ðŸš€ Starting text generation with: 'the'\n",
      "ðŸ“Š Corpus size: 152,991 tokens\n",
      "ðŸŽ¯ Target length: 10 words\n",
      "--------------------------------------------------\n",
      "Step 1: Looking for words after 'the'...\n",
      "   Top candidates: [('company', 225), ('U.S.', 137), ('government', 79)]\n",
      "   âœ… Predicted: 'quake' (frequency: 2)\n",
      "Step 2: Looking for words after 'quake'...\n",
      "   Top candidates: [('jolted', 1), ('cracked', 1), ('measured', 1)]\n",
      "   âœ… Predicted: 'measured' (frequency: 1)\n",
      "Step 3: Looking for words after 'measured'...\n",
      "   Top candidates: [('by', 1), ('6.25', 1)]\n",
      "   âœ… Predicted: 'by' (frequency: 1)\n",
      "Step 4: Looking for words after 'by'...\n",
      "   Top candidates: [('the', 149), ('a', 41), ('Standard', 6)]\n",
      "   âœ… Predicted: 'commercial' (frequency: 2)\n",
      "Step 5: Looking for words after 'commercial'...\n",
      "   Top candidates: [('banks', 13), ('bank', 9), ('paper', 7)]\n",
      "   âœ… Predicted: 'Credit' (frequency: 4)\n",
      "Step 6: Looking for words after 'Credit'...\n",
      "   Top candidates: [('card', 8), ('and', 5), ('Co', 3)]\n",
      "   âœ… Predicted: 'card' (frequency: 8)\n",
      "Step 7: Looking for words after 'card'...\n",
      "   Top candidates: [('by', 1), ('6.25', 1)]\n",
      "   âœ… Predicted: 'by' (frequency: 1)\n",
      "Step 4: Looking for words after 'by'...\n",
      "   Top candidates: [('the', 149), ('a', 41), ('Standard', 6)]\n",
      "   âœ… Predicted: 'commercial' (frequency: 2)\n",
      "Step 5: Looking for words after 'commercial'...\n",
      "   Top candidates: [('banks', 13), ('bank', 9), ('paper', 7)]\n",
      "   âœ… Predicted: 'Credit' (frequency: 4)\n",
      "Step 6: Looking for words after 'Credit'...\n",
      "   Top candidates: [('card', 8), ('and', 5), ('Co', 3)]\n",
      "   âœ… Predicted: 'card' (frequency: 8)\n",
      "Step 7: Looking for words after 'card'...\n",
      "   Top candidates: [('receivables', 2), ('receivables,', 2), ('operation.', 2)]\n",
      "   âœ… Predicted: 'receivables' (frequency: 2)\n",
      "Step 8: Looking for words after 'receivables'...\n",
      "   Top candidates: [('via', 1), ('because', 1), ('through', 1)]\n",
      "   âœ… Predicted: 'because' (frequency: 1)\n",
      "Step 9: Looking for words after 'because'...\n",
      "   Top candidates: [('of', 37), ('the', 14), ('it', 11)]\n",
      "   âœ… Predicted: 'of' (frequency: 37)\n",
      "--------------------------------------------------\n",
      "ðŸŽ‰ Generation complete! Generated 10 words.\n",
      "\n",
      "ðŸ”¥ Final Result: the quake measured by commercial Credit card receivables because of\n",
      "\n",
      "   Top candidates: [('receivables', 2), ('receivables,', 2), ('operation.', 2)]\n",
      "   âœ… Predicted: 'receivables' (frequency: 2)\n",
      "Step 8: Looking for words after 'receivables'...\n",
      "   Top candidates: [('via', 1), ('because', 1), ('through', 1)]\n",
      "   âœ… Predicted: 'because' (frequency: 1)\n",
      "Step 9: Looking for words after 'because'...\n",
      "   Top candidates: [('of', 37), ('the', 14), ('it', 11)]\n",
      "   âœ… Predicted: 'of' (frequency: 37)\n",
      "--------------------------------------------------\n",
      "ðŸŽ‰ Generation complete! Generated 10 words.\n",
      "\n",
      "ðŸ”¥ Final Result: the quake measured by commercial Credit card receivables because of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = generate_text(\"the\", target_length=10)\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f84ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXAMPLE 2: Starting with 'is'\n",
      "============================================================\n",
      "ðŸš€ Starting text generation with: 'is'\n",
      "ðŸ“Š Corpus size: 152,991 tokens\n",
      "ðŸŽ¯ Target length: 8 words\n",
      "--------------------------------------------------\n",
      "Step 1: Looking for words after 'is'...\n",
      "   Top candidates: [('expected', 49), ('a', 40), ('not', 40)]\n",
      "   âœ… Predicted: 'not' (frequency: 40)\n",
      "Step 2: Looking for words after 'not'...\n",
      "   Top candidates: [('be', 31), ('have', 12), ('to', 11)]\n",
      "   âœ… Predicted: 'be' (frequency: 31)\n",
      "Step 3: Looking for words after 'be'...\n",
      "   Top candidates: [('used', 28), ('a', 27), ('the', 19)]\n",
      "   âœ… Predicted: 'combined' (frequency: 1)\n",
      "Step 4: Looking for words after 'combined'...\n",
      "   Top candidates: [('pays', 8), ('sales', 3), ('with', 2)]\n",
      "   âœ… Predicted: '1986' (frequency: 1)\n",
      "Step 5: Looking for words after '1986'...\n",
      "   Top candidates: [('and', 23), ('net', 13), ('was', 6)]\n",
      "   âœ… Predicted: 'JAKARTA,' (frequency: 1)\n",
      "Step 6: Looking for words after 'JAKARTA,'...\n",
      "   Top candidates: [('March', 11)]\n",
      "   âœ… Predicted: 'March' (frequency: 11)\n",
      "Step 7: Looking for words after 'March'...\n",
      "   Top candidates: [('2', 565), ('3', 124), ('31', 27)]\n",
      "   âœ… Predicted: '2' (frequency: 565)\n",
      "--------------------------------------------------\n",
      "ðŸŽ‰ Generation complete! Generated 8 words.\n",
      "\n",
      "ðŸ”¥ Final Result: is not be combined 1986 JAKARTA, March 2\n",
      "\n",
      "   Top candidates: [('pays', 8), ('sales', 3), ('with', 2)]\n",
      "   âœ… Predicted: '1986' (frequency: 1)\n",
      "Step 5: Looking for words after '1986'...\n",
      "   Top candidates: [('and', 23), ('net', 13), ('was', 6)]\n",
      "   âœ… Predicted: 'JAKARTA,' (frequency: 1)\n",
      "Step 6: Looking for words after 'JAKARTA,'...\n",
      "   Top candidates: [('March', 11)]\n",
      "   âœ… Predicted: 'March' (frequency: 11)\n",
      "Step 7: Looking for words after 'March'...\n",
      "   Top candidates: [('2', 565), ('3', 124), ('31', 27)]\n",
      "   âœ… Predicted: '2' (frequency: 565)\n",
      "--------------------------------------------------\n",
      "ðŸŽ‰ Generation complete! Generated 8 words.\n",
      "\n",
      "ðŸ”¥ Final Result: is not be combined 1986 JAKARTA, March 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = generate_text(\"is\", target_length=8)\n",
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fed565",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = generate_text(\"the company\", target_length=12)\n",
    "print(result3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f422250",
   "metadata": {},
   "source": [
    "## Custom Generation\n",
    "\n",
    "Experiment with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "your_starting_word = \"market\"\n",
    "desired_length = 15\n",
    "\n",
    "result_custom = generate_text(your_starting_word, target_length=desired_length)\n",
    "print(result_custom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
