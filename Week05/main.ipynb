{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3496b377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1454b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x README.txt\n",
      "x all-exchanges-strings.lc.txt\n",
      "x all-orgs-strings.lc.txt\n",
      "x all-people-strings.lc.txt\n",
      "x all-places-strings.lc.txt\n",
      "x all-topics-strings.lc.txt\n",
      "x cat-descriptions_120396.txt\n",
      "x feldman-cia-worldfactbook-data.txt\n",
      "x lewis.dtd\n",
      "x reut2-000.sgm\n",
      "x reut2-001.sgm\n",
      "x reut2-002.sgm\n",
      "x reut2-003.sgm\n",
      "x reut2-004.sgm\n",
      "x reut2-005.sgm\n",
      "x reut2-006.sgm\n",
      "x reut2-007.sgm\n",
      "x reut2-008.sgm\n",
      "x reut2-009.sgm\n",
      "x reut2-010.sgm\n",
      "x reut2-011.sgm\n",
      "x reut2-012.sgm\n",
      "x reut2-013.sgm\n",
      "x reut2-014.sgm\n",
      "x reut2-015.sgm\n",
      "x reut2-016.sgm\n",
      "x reut2-017.sgm\n",
      "x reut2-018.sgm\n",
      "x reut2-019.sgm\n",
      "x reut2-020.sgm\n",
      "x reut2-021.sgm\n"
     ]
    }
   ],
   "source": [
    "!tar -xvf week05.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced08559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the archive:\n",
      "- README.txt\n",
      "- all-exchanges-strings.lc.txt\n",
      "- all-orgs-strings.lc.txt\n",
      "- all-people-strings.lc.txt\n",
      "- all-places-strings.lc.txt\n",
      "- all-topics-strings.lc.txt\n",
      "- cat-descriptions_120396.txt\n",
      "- feldman-cia-worldfactbook-data.txt\n",
      "- lewis.dtd\n",
      "- reut2-000.sgm\n",
      "- reut2-001.sgm\n",
      "- reut2-002.sgm\n",
      "- reut2-003.sgm\n",
      "- reut2-004.sgm\n",
      "- reut2-005.sgm\n",
      "- reut2-006.sgm\n",
      "- reut2-007.sgm\n",
      "- reut2-008.sgm\n",
      "- reut2-009.sgm\n",
      "- reut2-010.sgm\n",
      "- reut2-011.sgm\n",
      "- reut2-012.sgm\n",
      "- reut2-013.sgm\n",
      "- reut2-014.sgm\n",
      "- reut2-015.sgm\n",
      "- reut2-016.sgm\n",
      "- reut2-017.sgm\n",
      "- reut2-018.sgm\n",
      "- reut2-019.sgm\n",
      "- reut2-020.sgm\n",
      "- reut2-021.sgm\n",
      "\n",
      "Extraction completed!\n",
      "Files in current directory: ['all-exchanges-strings.lc.txt', 'all-orgs-strings.lc.txt', 'all-people-strings.lc.txt', 'all-places-strings.lc.txt', 'all-topics-strings.lc.txt', 'cat-descriptions_120396.txt', 'feldman-cia-worldfactbook-data.txt', 'lewis.dtd', 'main.ipynb', 'README.txt', 'reut2-000.sgm', 'reut2-001.sgm', 'reut2-002.sgm', 'reut2-003.sgm', 'reut2-004.sgm', 'reut2-005.sgm', 'reut2-006.sgm', 'reut2-007.sgm', 'reut2-008.sgm', 'reut2-009.sgm', 'reut2-010.sgm', 'reut2-011.sgm', 'reut2-012.sgm', 'reut2-013.sgm', 'reut2-014.sgm', 'reut2-015.sgm', 'reut2-016.sgm', 'reut2-017.sgm', 'reut2-018.sgm', 'reut2-019.sgm', 'reut2-020.sgm', 'reut2-021.sgm', 'week05.tar.gz']\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Extract tar.gz file (recommended approach)\n",
    "import tarfile\n",
    "import os\n",
    "\n",
    "# Extract the tar.gz file with proper filter for security\n",
    "with tarfile.open('week05.tar.gz', 'r:gz') as tar:\n",
    "    # Use filter='data' to handle the deprecation warning\n",
    "    tar.extractall(filter='data')\n",
    "    \n",
    "    # List all files in the archive\n",
    "    print(\"Files in the archive:\")\n",
    "    for member in tar.getmembers():\n",
    "        print(f\"- {member.name}\")\n",
    "\n",
    "print(\"\\nExtraction completed!\")\n",
    "print(\"Files in current directory:\", os.listdir('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a877361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files in the tar.gz:\n",
      "- README.txt (size: 36388 bytes)\n",
      "- all-exchanges-strings.lc.txt (size: 186 bytes)\n",
      "- all-orgs-strings.lc.txt (size: 316 bytes)\n",
      "- all-people-strings.lc.txt (size: 2474 bytes)\n",
      "- all-places-strings.lc.txt (size: 1721 bytes)\n",
      "- all-topics-strings.lc.txt (size: 1005 bytes)\n",
      "- cat-descriptions_120396.txt (size: 28194 bytes)\n",
      "- feldman-cia-worldfactbook-data.txt (size: 273802 bytes)\n",
      "- lewis.dtd (size: 1485 bytes)\n",
      "- reut2-000.sgm (size: 1324350 bytes)\n",
      "- reut2-001.sgm (size: 1254440 bytes)\n",
      "- reut2-002.sgm (size: 1217495 bytes)\n",
      "- reut2-003.sgm (size: 1298721 bytes)\n",
      "- reut2-004.sgm (size: 1321623 bytes)\n",
      "- reut2-005.sgm (size: 1388644 bytes)\n",
      "- reut2-006.sgm (size: 1254765 bytes)\n",
      "- reut2-007.sgm (size: 1256772 bytes)\n",
      "- reut2-008.sgm (size: 1410117 bytes)\n",
      "- reut2-009.sgm (size: 1338903 bytes)\n",
      "- reut2-010.sgm (size: 1371071 bytes)\n",
      "- reut2-011.sgm (size: 1304117 bytes)\n",
      "- reut2-012.sgm (size: 1323584 bytes)\n",
      "- reut2-013.sgm (size: 1129687 bytes)\n",
      "- reut2-014.sgm (size: 1128671 bytes)\n",
      "- reut2-015.sgm (size: 1258665 bytes)\n",
      "- reut2-016.sgm (size: 1316417 bytes)\n",
      "- reut2-017.sgm (size: 1546911 bytes)\n",
      "- reut2-018.sgm (size: 1258819 bytes)\n",
      "- reut2-019.sgm (size: 1261780 bytes)\n",
      "- reut2-020.sgm (size: 1049566 bytes)\n",
      "- reut2-021.sgm (size: 621648 bytes)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Content preview of README.txt:\n",
      "\n",
      "          Reuters-21578 text categorization test collection\n",
      "                        Distribution 1.0\n",
      "                       README file (v 1.2)\n",
      "                        26 September 1997\n",
      "\n",
      "                         David D. Lewis\n",
      "                      AT&T Labs - Research     \n",
      "                     lewis@research.att.com\n",
      "\n",
      "I. Introduction\n",
      "\n",
      "   This README describes Distribution 1.0 of the Reuters-21578 text\n",
      "categorization test collection, a resource for research in information\n",
      "retrieval, machine lear\n",
      "- README.txt (size: 36388 bytes)\n",
      "- all-exchanges-strings.lc.txt (size: 186 bytes)\n",
      "- all-orgs-strings.lc.txt (size: 316 bytes)\n",
      "- all-people-strings.lc.txt (size: 2474 bytes)\n",
      "- all-places-strings.lc.txt (size: 1721 bytes)\n",
      "- all-topics-strings.lc.txt (size: 1005 bytes)\n",
      "- cat-descriptions_120396.txt (size: 28194 bytes)\n",
      "- feldman-cia-worldfactbook-data.txt (size: 273802 bytes)\n",
      "- lewis.dtd (size: 1485 bytes)\n",
      "- reut2-000.sgm (size: 1324350 bytes)\n",
      "- reut2-001.sgm (size: 1254440 bytes)\n",
      "- reut2-002.sgm (size: 1217495 bytes)\n",
      "- reut2-003.sgm (size: 1298721 bytes)\n",
      "- reut2-004.sgm (size: 1321623 bytes)\n",
      "- reut2-005.sgm (size: 1388644 bytes)\n",
      "- reut2-006.sgm (size: 1254765 bytes)\n",
      "- reut2-007.sgm (size: 1256772 bytes)\n",
      "- reut2-008.sgm (size: 1410117 bytes)\n",
      "- reut2-009.sgm (size: 1338903 bytes)\n",
      "- reut2-010.sgm (size: 1371071 bytes)\n",
      "- reut2-011.sgm (size: 1304117 bytes)\n",
      "- reut2-012.sgm (size: 1323584 bytes)\n",
      "- reut2-013.sgm (size: 1129687 bytes)\n",
      "- reut2-014.sgm (size: 1128671 bytes)\n",
      "- reut2-015.sgm (size: 1258665 bytes)\n",
      "- reut2-016.sgm (size: 1316417 bytes)\n",
      "- reut2-017.sgm (size: 1546911 bytes)\n",
      "- reut2-018.sgm (size: 1258819 bytes)\n",
      "- reut2-019.sgm (size: 1261780 bytes)\n",
      "- reut2-020.sgm (size: 1049566 bytes)\n",
      "- reut2-021.sgm (size: 621648 bytes)\n",
      "\n",
      "==================================================\n",
      "\n",
      "Content preview of README.txt:\n",
      "\n",
      "          Reuters-21578 text categorization test collection\n",
      "                        Distribution 1.0\n",
      "                       README file (v 1.2)\n",
      "                        26 September 1997\n",
      "\n",
      "                         David D. Lewis\n",
      "                      AT&T Labs - Research     \n",
      "                     lewis@research.att.com\n",
      "\n",
      "I. Introduction\n",
      "\n",
      "   This README describes Distribution 1.0 of the Reuters-21578 text\n",
      "categorization test collection, a resource for research in information\n",
      "retrieval, machine lear\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Read files directly from tar.gz without extracting\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open('week05.tar.gz', 'r:gz') as tar:\n",
    "    # List all files in the archive\n",
    "    print(\"Available files in the tar.gz:\")\n",
    "    for member in tar.getmembers():\n",
    "        if member.isfile():\n",
    "            print(f\"- {member.name} (size: {member.size} bytes)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Read a specific file from the archive (example)\n",
    "    # Replace 'filename.txt' with an actual file name from your archive\n",
    "    try:\n",
    "        # Example: reading the first text file found\n",
    "        for member in tar.getmembers():\n",
    "            if member.isfile() and member.name.endswith('.txt'):\n",
    "                file_obj = tar.extractfile(member)\n",
    "                if file_obj:\n",
    "                    content = file_obj.read().decode('utf-8', errors='ignore')\n",
    "                    print(f\"\\nContent preview of {member.name}:\")\n",
    "                    print(content[:500])  # Show first 500 characters\n",
    "                    break\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c68f898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files after extraction:\n",
      "- README.txt\n",
      "- all-exchanges-strings.lc.txt\n",
      "- all-orgs-strings.lc.txt\n",
      "- all-people-strings.lc.txt\n",
      "- all-places-strings.lc.txt\n",
      "- all-topics-strings.lc.txt\n",
      "- cat-descriptions_120396.txt\n",
      "- feldman-cia-worldfactbook-data.txt\n",
      "- lewis.dtd\n",
      "- main.ipynb\n",
      "- reut2-000.sgm\n",
      "- reut2-001.sgm\n",
      "- reut2-002.sgm\n",
      "- reut2-003.sgm\n",
      "- reut2-004.sgm\n",
      "- reut2-005.sgm\n",
      "- reut2-006.sgm\n",
      "- reut2-007.sgm\n",
      "- reut2-008.sgm\n",
      "- reut2-009.sgm\n",
      "- reut2-010.sgm\n",
      "- reut2-011.sgm\n",
      "- reut2-012.sgm\n",
      "- reut2-013.sgm\n",
      "- reut2-014.sgm\n",
      "- reut2-015.sgm\n",
      "- reut2-016.sgm\n",
      "- reut2-017.sgm\n",
      "- reut2-018.sgm\n",
      "- reut2-019.sgm\n",
      "- reut2-020.sgm\n",
      "- reut2-021.sgm\n",
      "- week05.tar.gz\n",
      "\n",
      "==================================================\n",
      "\n",
      "Reading text file: all-exchanges-strings.lc.txt\n",
      "File size: 186 characters\n",
      "Preview: amex\n",
      "ase\n",
      "asx\n",
      "biffex\n",
      "bse\n",
      "cboe\n",
      "cbt\n",
      "cme\n",
      "comex\n",
      "cse\n",
      "fox\n",
      "fse\n",
      "hkse\n",
      "ipe\n",
      "jse\n",
      "klce\n",
      "klse\n",
      "liffe\n",
      "lme\n",
      "lse\n",
      "mase\n",
      "mise\n",
      "mnse\n",
      "mose\n",
      "nasdaq\n",
      "nyce\n",
      "nycsce\n",
      "nymex\n",
      "nyse\n",
      "ose\n",
      "pse\n",
      "set\n",
      "simex\n",
      "sse\n",
      "stse\n",
      "tose\n",
      "tse\n",
      "wce\n",
      "zse\n",
      "\n",
      "\n",
      "Reading text file: all-orgs-strings.lc.txt\n",
      "File size: 316 characters\n",
      "Preview: adb-africa\n",
      "adb-asia\n",
      "aibd\n",
      "aid\n",
      "anrpc\n",
      "asean\n",
      "atpc\n",
      "bis\n",
      "cipec\n",
      "comecon\n",
      "ec\n",
      "eca\n",
      "ecafe\n",
      "ece\n",
      "ecla\n",
      "ecsc\n",
      "ecwa\n",
      "efta\n",
      "eib\n",
      "emcf\n",
      "escap\n",
      "euratom\n",
      "fao\n",
      "gatt\n",
      "gcc\n",
      "geplacea\n",
      "iaea\n",
      "iata\n",
      "icco\n",
      "ico-coffee\n",
      "ico-islam\n",
      "ida\n",
      "iea\n",
      "iisi\n",
      "ilo\n",
      "i\n",
      "\n",
      "Reading text file: all-people-strings.lc.txt\n",
      "File size: 2474 characters\n",
      "Preview: abdel-hadi-kandeel\n",
      "alfonsin\n",
      "alhaji-abdul-ahmed\n",
      "alptemocin\n",
      "amato\n",
      "andersen\n",
      "andriessen\n",
      "aqazadeh\n",
      "aquino\n",
      "arafat\n",
      "babangida\n",
      "balladur\n",
      "bangemann\n",
      "barreto\n",
      "berge\n",
      "beteta\n",
      "blix\n",
      "boesky\n",
      "bond\n",
      "botha\n",
      "bouey\n",
      "braks\n",
      "bresser-\n",
      "\n",
      "Reading text file: all-places-strings.lc.txt\n",
      "File size: 1721 characters\n",
      "Preview: afghanistan\n",
      "albania \n",
      "algeria \n",
      "american-samoa\n",
      "andorra \n",
      "angola  \n",
      "anguilla\n",
      "antigua \n",
      "argentina  \n",
      "aruba\n",
      "australia  \n",
      "austria \n",
      "bahamas \n",
      "bahrain \n",
      "bangladesh \n",
      "barbados\n",
      "belgium \n",
      "belize  \n",
      "benin\n",
      "bermuda \n",
      "bhutan  \n",
      "\n",
      "Reading text file: all-topics-strings.lc.txt\n",
      "File size: 1005 characters\n",
      "Preview: acq\n",
      "alum\n",
      "austdlr\n",
      "austral\n",
      "barley\n",
      "bfr\n",
      "bop\n",
      "can\n",
      "carcass\n",
      "castor-meal\n",
      "castor-oil\n",
      "castorseed\n",
      "citruspulp\n",
      "cocoa\n",
      "coconut\n",
      "coconut-oil\n",
      "coffee\n",
      "copper\n",
      "copra-cake\n",
      "corn\n",
      "corn-oil\n",
      "cornglutenfeed\n",
      "cotton \n",
      "cotton-meal\n",
      "cot\n",
      "\n",
      "Reading text file: cat-descriptions_120396.txt\n",
      "File size: 28194 characters\n",
      "Preview: \n",
      "Some notes on the Reuters Categories\n",
      "David D. Lewis\n",
      "3-Dec-96\n",
      "\n",
      "  The letter W. Bruce Croft received from Phil Hayes (March 9, 1990)\n",
      "gave a list of 135 TOPICS categories, which were used in HAYES89.  I\n",
      "\n",
      "Reading text file: feldman-cia-worldfactbook-data.txt\n",
      "File size: 273802 characters\n",
      "Preview: This is a set of Prolog assertions for facts about countries, kindly\n",
      "made available by Ronen Feldman of Bar-Ilan University. It was\n",
      "extracted by Ronen Feldman and Amir Zilberstein from \"The Project\n",
      "Gu\n",
      "\n",
      "Reading text file: README.txt\n",
      "File size: 36388 characters\n",
      "Preview: \n",
      "          Reuters-21578 text categorization test collection\n",
      "                        Distribution 1.0\n",
      "                       README file (v 1.2)\n",
      "                        26 September 1997\n",
      "\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "# Method 3: Working with extracted files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# After extraction, you can work with the files normally\n",
    "current_files = [f for f in os.listdir('.') if os.path.isfile(f)]\n",
    "print(\"Available files after extraction:\")\n",
    "for file in sorted(current_files):\n",
    "    print(f\"- {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Example: Read different types of files based on extension\n",
    "for file in current_files:\n",
    "    if file.endswith('.txt'):\n",
    "        print(f\"\\nReading text file: {file}\")\n",
    "        try:\n",
    "            with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "                print(f\"File size: {len(content)} characters\")\n",
    "                print(\"Preview:\", content[:200])\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "    \n",
    "    elif file.endswith('.csv'):\n",
    "        print(f\"\\nReading CSV file: {file}\")\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            print(f\"Shape: {df.shape}\")\n",
    "            print(\"Columns:\", list(df.columns))\n",
    "            print(\"\\nFirst few rows:\")\n",
    "            print(df.head())\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file}: {e}\")\n",
    "        break  # Only show first CSV for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18ba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import trigrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')\n",
    "\n",
    "words = nltk.word_tokenize(' '.join(reuters.words()))\n",
    "tri_grams = list(trigrams(words))\n",
    "\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "for w1, w2, w3 in tri_grams:\n",
    "    model[(w1, w2)][w3] += 1\n",
    "\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count\n",
    "\n",
    "\n",
    "def predict_next_word(w1, w2):\n",
    "    next_word_probs = model[w1, w2]\n",
    "    if next_word_probs:\n",
    "        return max(next_word_probs, key=next_word_probs.get)\n",
    "    else:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "\n",
    "print(\"Next Word:\", predict_next_word('the', 'stock'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
